<!DOCTYPE html>
<html>
<head>
    <title>Desktop Debug Test</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .test { margin: 20px 0; padding: 20px; border: 1px solid #ccc; }
        .success { background: #d4edda; }
        .error { background: #f8d7da; }
        button { padding: 10px 20px; margin: 5px; }
    </style>
</head>
<body>
    <h1>Desktop Compatibility Test</h1>
    
    <div class="test" id="browser-test">
        <h2>1. Browser Check</h2>
        <p id="browser-info">Detecting...</p>
    </div>
    
    <div class="test" id="mic-test">
        <h2>2. Microphone Test</h2>
        <button onclick="testMicrophone()">Test Microphone</button>
        <p id="mic-result"></p>
    </div>
    
    <div class="test" id="speech-test">
        <h2>3. Speech Recognition Test</h2>
        <button onclick="testSpeechRecognition()">Test Speech Recognition</button>
        <p id="speech-result">Say something after clicking...</p>
    </div>
    
    <div class="test" id="audio-test">
        <h2>4. Audio Context Test</h2>
        <button onclick="testAudioContext()">Test Audio</button>
        <canvas id="test-canvas" width="300" height="60" style="border:1px solid #ccc;"></canvas>
    </div>
    
    <div class="test" id="api-test">
        <h2>5. API Test</h2>
        <button onclick="testAPI()">Test Backend API</button>
        <p id="api-result"></p>
    </div>
    
    <script>
        // 1. Browser info
        const browserInfo = document.getElementById('browser-info');
        browserInfo.innerHTML = `
            User Agent: ${navigator.userAgent}<br>
            Platform: ${navigator.platform}<br>
            Cookies: ${navigator.cookieEnabled ? 'Enabled' : 'Disabled'}<br>
            Online: ${navigator.onLine ? 'Yes' : 'No'}<br>
            Media Devices: ${navigator.mediaDevices ? 'Supported' : 'Not Supported'}
        `;
        
        // 2. Microphone test
        async function testMicrophone() {
            const result = document.getElementById('mic-result');
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                result.innerHTML = '<span style="color:green">‚úÖ Microphone works!</span>';
                result.parentElement.classList.add('success');
                
                // Test audio levels
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(stream);
                const analyser = audioContext.createAnalyser();
                source.connect(analyser);
                
                setTimeout(() => {
                    stream.getTracks().forEach(track => track.stop());
                    audioContext.close();
                }, 1000);
                
            } catch (error) {
                result.innerHTML = `<span style="color:red">‚ùå Error: ${error.name} - ${error.message}</span>`;
                result.parentElement.classList.add('error');
            }
        }
        
        // 3. Speech recognition test
        function testSpeechRecognition() {
            const result = document.getElementById('speech-result');
            
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                result.innerHTML = '<span style="color:red">‚ùå Speech recognition not supported</span>';
                return;
            }
            
            const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
            const recognition = new SpeechRecognition();
            
            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'en-US';
            
            recognition.onstart = () => {
                result.innerHTML = 'üé§ Listening... Speak now!';
            };
            
            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                result.innerHTML = `<span style="color:green">‚úÖ Heard: "${transcript}"</span>`;
                result.parentElement.classList.add('success');
            };
            
            recognition.onerror = (event) => {
                result.innerHTML = `<span style="color:red">‚ùå Error: ${event.error}</span>`;
                result.parentElement.classList.add('error');
            };
            
            recognition.start();
        }
        
        // 4. Audio visualization test
        async function testAudioContext() {
            const canvas = document.getElementById('test-canvas');
            const ctx = canvas.getContext('2d');
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(stream);
                const analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                source.connect(analyser);
                
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                function draw() {
                    requestAnimationFrame(draw);
                    analyser.getByteFrequencyData(dataArray);
                    
                    ctx.fillStyle = '#f0f0f0';
                    ctx.fillRect(0, 0, canvas.width, canvas.height);
                    
                    const barWidth = (canvas.width / bufferLength) * 2.5;
                    let x = 0;
                    
                    for (let i = 0; i < bufferLength; i++) {
                        const barHeight = dataArray[i];
                        
                        ctx.fillStyle = `rgb(${barHeight + 100}, 50, 150)`;
                        ctx.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
                        
                        x += barWidth + 1;
                    }
                }
                
                draw();
                
                // Stop after 5 seconds
                setTimeout(() => {
                    stream.getTracks().forEach(track => track.stop());
                    audioContext.close();
                    ctx.fillStyle = '#f0f0f0';
                    ctx.fillRect(0, 0, canvas.width, canvas.height);
                }, 5000);
                
            } catch (error) {
                console.error('Audio test error:', error);
            }
        }
        
        // 5. API test
        async function testAPI() {
            const result = document.getElementById('api-result');
            
            try {
                const response = await fetch('/api/analyze_text', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: 'Hello, this is a test' })
                });
                
                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}`);
                }
                
                const data = await response.json();
                result.innerHTML = `<span style="color:green">‚úÖ API works! Response: ${JSON.stringify(data).substring(0, 100)}...</span>`;
                result.parentElement.classList.add('success');
                
            } catch (error) {
                result.innerHTML = `<span style="color:red">‚ùå API Error: ${error.message}</span>`;
                result.parentElement.classList.add('error');
            }
        }
    </script>
</body>
</html>